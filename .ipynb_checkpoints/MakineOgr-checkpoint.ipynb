{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4811285",
   "metadata": {},
   "source": [
    "### Makine Öğrenmesi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250152d",
   "metadata": {},
   "source": [
    "### İhtiyacımız olacak olan kütüphaneler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d6d7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sn\n",
    "#import sys\n",
    "#from sklearn.preprocessing import Imputer\n",
    "#import numpy\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "import warnings\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.metrics import roc_curve\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "# Sürümden kaynaklı hatalı göz ardı etmek için kullanıyoruz.\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Keras specific\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "117b366e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Current Loan Amount  Credit Score  Annual Income  Monthly Debt\n",
      "0                 0.000181      0.004347       0.012999      0.018683\n",
      "1                 0.000079      0.004271       0.012028      0.016291\n",
      "2                 0.000046      0.004126       0.005460      0.003733\n",
      "3                 0.000052      0.004230       0.004889      0.007461\n",
      "4                 0.000095      0.004329       0.011038      0.017561\n",
      "...                    ...           ...            ...           ...\n",
      "10348             0.003440      0.006273       0.008581      0.008198\n",
      "10349             0.003440      0.006273       0.008581      0.008198\n",
      "10350             0.003440      0.006273       0.008581      0.008198\n",
      "10351             0.003440      0.006273       0.008581      0.008198\n",
      "10352             0.003440      0.006273       0.008581      0.008198\n",
      "\n",
      "[10353 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#listenin ortalama hesabunı verir\n",
    "def findAverage(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "\n",
    "#df=pd.read_csv('bank_marketing_dataset.csv')\n",
    "df=pd.read_csv('credit_test.csv')\n",
    "        \n",
    "#Credit_Score Prep data\n",
    "arr = df[\"Credit Score\"].values\n",
    "\n",
    "filter_credit_score = []\n",
    "\n",
    "#ortalamasını bulabilmek için nan değerlerin olmadığı arraya ekleme yapıyoruz.\n",
    "for element in arr:\n",
    "    if str(element) != 'nan':\n",
    "         filter_credit_score.append(element)\n",
    "         \n",
    "        \n",
    "        \n",
    "    \n",
    "average_filter_creditscore=findAverage(filter_credit_score)\n",
    "\n",
    "\n",
    "\n",
    "#ortalama değer atayarak nan değerlerin sonuca etki etmesi engellendi\n",
    "for i in range(len(df[\"Credit Score\"].values)):\n",
    "     if str(df[\"Credit Score\"].values[i]) == 'nan':\n",
    "            df[\"Credit Score\"].values[i]=average_filter_creditscore\n",
    "        \n",
    "\n",
    "\n",
    "#Credit_Score Prep data End\n",
    "\n",
    "#Annual Income Prep data\n",
    "arr = df[\"Annual Income\"].values\n",
    "\n",
    "filter_credit_score = []\n",
    "\n",
    "#ortalamasını bulabilmek için nan değerlerin olmadığı arraya ekleme yapıyoruz.\n",
    "for element in arr:\n",
    "    if str(element) != 'nan':\n",
    "         filter_credit_score.append(element)\n",
    "         \n",
    "        \n",
    "        \n",
    "    \n",
    "average_filter_Annual_Income=findAverage(filter_credit_score)\n",
    "\n",
    "\n",
    "\n",
    "#ortalama değer atayarak nan değerlerin sonuca etki etmesi engellendi\n",
    "for i in range(len(df[\"Annual Income\"].values)):\n",
    "     if str(df[\"Annual Income\"].values[i]) == 'nan':\n",
    "            df[\"Annual Income\"].values[i]=average_filter_Annual_Income\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "#for i in range(len(df[\"Annual Income\"].values)):\n",
    "#           print(df[\"Annual Income\"].values[i])\n",
    "\n",
    "#Annual Income Prep data End\n",
    "\n",
    "\n",
    "#Current Loan Amount Prep data**\n",
    "arr = df[\"Current Loan Amount\"].values\n",
    "\n",
    "filter_credit_score = []\n",
    "\n",
    "#ortalamasını bulabilmek için nan değerlerin olmadığı arraya ekleme yapıyoruz.\n",
    "for element in arr:\n",
    "    if str(element) != 'nan':\n",
    "         filter_credit_score.append(element)\n",
    "         \n",
    "        \n",
    "        \n",
    "    \n",
    "average_filter_currentLoan=findAverage(filter_credit_score)\n",
    "\n",
    "\n",
    "\n",
    "#ortalama değer atayarak nan değerlerin sonuca etki etmesi engellendi\n",
    "for i in range(len(df[\"Current Loan Amount\"].values)):\n",
    "     if str(df[\"Current Loan Amount\"].values[i]) == 'nan':\n",
    "            df[\"Current Loan Amount\"].values[i]=average_filter_currentLoan\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "#Current Loan Amount End\n",
    "\n",
    "\n",
    "\n",
    "#Monthly Debt Prep data**\n",
    "arr = df[\"Monthly Debt\"].values\n",
    "\n",
    "filter_credit_score = []\n",
    "\n",
    "#ortalamasını bulabilmek için nan değerlerin olmadığı arraya ekleme yapıyoruz.\n",
    "for element in arr:\n",
    "    if str(element) != 'nan':\n",
    "         filter_credit_score.append(element)\n",
    "         \n",
    "        \n",
    "        \n",
    "    \n",
    "average_filter_monthlydept=findAverage(filter_credit_score)\n",
    "\n",
    "\n",
    "\n",
    "#ortalama değer atayarak nan değerlerin sonuca etki etmesi engellendi\n",
    "for i in range(len(df[\"Monthly Debt\"].values)):\n",
    "     if str(df[\"Monthly Debt\"].values[i]) == 'nan':\n",
    "            df[\"Monthly Debt\"].values[i]=average_filter_monthlydept\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "#Monthly Debt Prep End\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Number of Credit Problems   Debt Prep data**\n",
    "arr = df[\"Number of Credit Problems\"].values\n",
    "\n",
    "\n",
    "#tahmin edilecek kolonun nan değerlerine default bir değer veriyoruz 4\n",
    "for i in range(len(arr)):\n",
    "         if str(df[\"Number of Credit Problems\"].values[i]) == 'nan':\n",
    "            df[\"Number of Credit Problems\"].values[i]=4\n",
    "            \n",
    "        \n",
    "#Number of Credit Problems   Debt Prep End\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Annual Income kolonuna Normalizasyon yapılarak dataset içerisine eklenmektedir.\n",
    "result = np.linalg.norm(df[\"Monthly Debt\"].values)\n",
    "\n",
    "normval_mondept=df[\"Monthly Debt\"].values/result\n",
    "\n",
    "for i in range(len(normval_mondept)):\n",
    "       df[\"Monthly Debt\"].values[i] = normval_mondept[i]\n",
    "          \n",
    "#Annual Income kolonuna Normalizasyon yapılarak dataset içerisine eklenmektedir(END).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Annual Income kolonuna Normalizasyon yapılarak dataset içerisine eklenmektedir.\n",
    "result = np.linalg.norm(df[\"Annual Income\"].values)\n",
    "\n",
    "normval_annual=df[\"Annual Income\"].values/result\n",
    "\n",
    "for i in range(len(normval_annual)):\n",
    "       df[\"Annual Income\"].values[i] = normval_annual[i]\n",
    "          \n",
    "#Annual Income kolonuna Normalizasyon yapılarak dataset içerisine eklenmektedir(END).\n",
    "\n",
    "\n",
    "\n",
    "#Credit Score kolonuna Normalizasyon yapılarak dataset içerisine eklenmektedir.\n",
    "result = np.linalg.norm(df[\"Credit Score\"].values)\n",
    "\n",
    "normval_creditscore=df[\"Credit Score\"].values/result\n",
    "\n",
    "for i in range(len(normval_creditscore)):\n",
    "       df[\"Credit Score\"].values[i] = normval_creditscore[i]\n",
    "          \n",
    "#Credit Score kolonuna Normalizasyon yapılarak dataset içerisine eklenmektedir(END).\n",
    "\n",
    "\n",
    "#Current Loan Amount kolonuna Normalizasyon yapılarak dataset içerisine eklenmektedir.\n",
    "result = np.linalg.norm(df[\"Current Loan Amount\"].values)\n",
    "\n",
    "normval_currentLoan=df[\"Current Loan Amount\"].values/result\n",
    "\n",
    "for i in range(len(normval_currentLoan)):\n",
    "       df[\"Current Loan Amount\"].values[i] = normval_currentLoan[i]\n",
    "          \n",
    "#Current Loan Amount kolonuna Normalizasyon yapılarak dataset içerisine eklenmektedir(END).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(df.shape)\n",
    "#print(df.head(15))\n",
    "#df.describe()\n",
    "\n",
    "y = df[\"Number of Credit Problems\"].values.reshape(-1,1)  #sütun haline getirdik\n",
    "print(y)\n",
    "x = df.drop([\"Loan ID\",\"Customer ID\"\n",
    "             ,\"Number of Credit Problems\"\n",
    "             ,\"Term\",\"Years in current job\"\n",
    "             ,\"Home Ownership\",\"Purpose\"\n",
    "             ,\"Years of Credit History\"\n",
    "             ,\"Months since last delinquent\"\n",
    "             ,\"Number of Open Accounts\"\n",
    "             ,\"Current Credit Balance\"\n",
    "             ,\"Maximum Open Credit\"\n",
    "             ,\"Bankruptcies\"\n",
    "             ,\"Tax Liens\"\n",
    "            \n",
    "            \n",
    "            ],axis=1)\n",
    "#print(x.head(5))\n",
    "\n",
    "#print(y.shape)\n",
    "#print(type(y))\n",
    "\n",
    "#last=df[\"Months since last delinquent\"].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "print(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d10f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verileri x input ve y output olarak ayırıyoruz\n",
    "#output müşteri ve ya abone olma durumu\n",
    "# çıkıtıyı istediğimiz formata alıyoruz.\n",
    "for cikti in y:\n",
    "    if cikti[0]=='no':\n",
    "        cikti[0]=0\n",
    "    else:\n",
    "        cikti[0]=1\n",
    "              \n",
    "\n",
    "                \n",
    "# string değerleri işleme alamayacağım için onlara kendim değer atadım \n",
    "for cikti in range(len(x['poutcome'].values)):\n",
    "    if x['poutcome'].values[cikti]=='nonexistent':\n",
    "         x['poutcome'].values[cikti]=2\n",
    "    if df['poutcome'].values[cikti]=='success':\n",
    "         x['poutcome'].values[cikti]=3\n",
    "    if df['poutcome'].values[cikti]=='failure':    \n",
    "         x['poutcome'].values[cikti]=1\n",
    "\n",
    "\n",
    "                      \n",
    "            \n",
    "# (meslekler) string  değerleri işleme alamayacağım için onlara kendim değer atadım \n",
    "for cikti in range(len(x['job'].values)):\n",
    "    if x['job'].values[cikti]=='admin.':\n",
    "         x['job'].values[cikti]=13\n",
    "    if x['job'].values[cikti]=='blue-collar':\n",
    "         x['job'].values[cikti]=12\n",
    "    if x['job'].values[cikti]=='entrepreneur':    \n",
    "         x['job'].values[cikti]=11\n",
    "    if x['job'].values[cikti]=='housemaid':    \n",
    "         x['job'].values[cikti]=10      \n",
    "    if x['job'].values[cikti]=='management':\n",
    "         x['job'].values[cikti]=9\n",
    "    if x['job'].values[cikti]=='retired':\n",
    "         x['job'].values[cikti]=8\n",
    "    if x['job'].values[cikti]=='self-employed':    \n",
    "         x['job'].values[cikti]=7\n",
    "    if x['job'].values[cikti]=='services':    \n",
    "         x['job'].values[cikti]=6      \n",
    "    if x['job'].values[cikti]=='student':\n",
    "         x['job'].values[cikti]=5\n",
    "    if x['job'].values[cikti]=='technician':\n",
    "         x['job'].values[cikti]=4\n",
    "    if x['job'].values[cikti]=='unknown':    \n",
    "         x['job'].values[cikti]=3\n",
    "    if x['job'].values[cikti]=='unemployed':    \n",
    "         x['job'].values[cikti]=2\n",
    "            \n",
    "            \n",
    "# string değerleri işleme alamayacağım için onlara kendim değer atadım \n",
    "for cikti in range(len(x['marital'].values)):\n",
    "    if x['marital'].values[cikti]=='divorced':\n",
    "         x['marital'].values[cikti]=2\n",
    "    if x['marital'].values[cikti]=='married':\n",
    "         x['marital'].values[cikti]=3\n",
    "    if x['marital'].values[cikti]=='single':    \n",
    "         x['marital'].values[cikti]=1\n",
    "    if x['marital'].values[cikti]=='unknown':    \n",
    "         x['marital'].values[cikti]=4\n",
    "\n",
    "for cikti in range(len(x['month'].values)):\n",
    "    if x['month'].values[cikti]=='jan':\n",
    "         x['month'].values[cikti]=1\n",
    "    if x['month'].values[cikti]=='feb':\n",
    "         x['month'].values[cikti]=2\n",
    "    if x['month'].values[cikti]=='mar':    \n",
    "         x['month'].values[cikti]=3\n",
    "    if x['month'].values[cikti]=='apr':    \n",
    "         x['month'].values[cikti]=4            \n",
    "    if x['month'].values[cikti]=='may':\n",
    "         x['month'].values[cikti]=5\n",
    "    if x['month'].values[cikti]=='jun':\n",
    "         x['month'].values[cikti]=6\n",
    "    if x['month'].values[cikti]=='jul':    \n",
    "         x['month'].values[cikti]=7\n",
    "    if x['month'].values[cikti]=='aug':    \n",
    "         x['month'].values[cikti]=8           \n",
    "    if x['month'].values[cikti]=='sep':\n",
    "         x['month'].values[cikti]=9\n",
    "    if x['month'].values[cikti]=='oct':\n",
    "         x['month'].values[cikti]=10\n",
    "    if x['month'].values[cikti]=='nov':    \n",
    "         x['month'].values[cikti]=11\n",
    "    if x['month'].values[cikti]=='dec':    \n",
    "         x['month'].values[cikti]=12\n",
    "\n",
    "for cikti in range(len(x['day_of_week'].values)):\n",
    "    if x['day_of_week'].values[cikti]=='mon':\n",
    "         x['day_of_week'].values[cikti]=1\n",
    "    if x['day_of_week'].values[cikti]=='tue':\n",
    "         x['day_of_week'].values[cikti]=2\n",
    "    if x['day_of_week'].values[cikti]=='wed':    \n",
    "         x['day_of_week'].values[cikti]=3\n",
    "    if x['day_of_week'].values[cikti]=='thu':    \n",
    "         x['day_of_week'].values[cikti]=4            \n",
    "    if x['day_of_week'].values[cikti]=='fri':    \n",
    "         x['day_of_week'].values[cikti]=5\n",
    "            \n",
    "            \n",
    "\n",
    "for cikti in range(len(x['default'].values)):\n",
    "    if x['default'].values[cikti]=='no':\n",
    "         x['default'].values[cikti]=3\n",
    "    if x['default'].values[cikti]=='yes':\n",
    "         x['default'].values[cikti]=1\n",
    "    if x['default'].values[cikti]=='unknown':    \n",
    "         x['default'].values[cikti]=2\n",
    "\n",
    "            \n",
    "for cikti in range(len(x['housing'].values)):\n",
    "    if x['housing'].values[cikti]=='no':\n",
    "         x['housing'].values[cikti]=3\n",
    "    if x['housing'].values[cikti]=='yes':\n",
    "         x['housing'].values[cikti]=1\n",
    "    if x['housing'].values[cikti]=='unknown':    \n",
    "         x['housing'].values[cikti]=2\n",
    "            \n",
    "\n",
    "for cikti in range(len(x['loan'].values)):\n",
    "    if x['loan'].values[cikti]=='no':\n",
    "         x['loan'].values[cikti]=3\n",
    "    if x['loan'].values[cikti]=='yes':\n",
    "         x['loan'].values[cikti]=1\n",
    "    if x['loan'].values[cikti]=='unknown':    \n",
    "         x['loan'].values[cikti]=2\n",
    "\n",
    "            \n",
    "for cikti in range(len(x['education'].values)):\n",
    "    if x['education'].values[cikti]=='basic.4y':\n",
    "         x['education'].values[cikti]=3\n",
    "    if x['education'].values[cikti]=='basic.6y':\n",
    "         x['education'].values[cikti]=4\n",
    "    if x['education'].values[cikti]=='basic.9y':    \n",
    "         x['education'].values[cikti]=5\n",
    "    if x['education'].values[cikti]=='high.school':\n",
    "         x['education'].values[cikti]=6\n",
    "    if x['education'].values[cikti]=='illiterate':\n",
    "         x['education'].values[cikti]=1\n",
    "    if x['education'].values[cikti]=='professional.course':    \n",
    "         x['education'].values[cikti]=8   \n",
    "    if x['education'].values[cikti]=='university.degree':\n",
    "         x['education'].values[cikti]=9\n",
    "    if x['education'].values[cikti]=='unknown':\n",
    "         x['education'].values[cikti]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d763a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "12fb24fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10353, 4)\n",
      "(10353, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf802f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3e53c0c",
   "metadata": {},
   "source": [
    "## Dataların eğitim ve test olacak şekilde ayrılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "620c5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x = np.asarray(x).astype('float32')\n",
    "#datayı eğitmek ve test için sklearn kutuphanesini kullanarak %80 train,%20 test olarak ayırıyoruz\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.4, random_state=42,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# elde ettiğimiz verilerin transposunu alıyoruz\n",
    "# backward ve predict işlemleri yaparken matrix hatasını gidermek için bunu yaptık, forward ı buna göre yeniledik \n",
    "x_train = X_train.T\n",
    "y_train = Y_train.T\n",
    "x_test = X_test.T\n",
    "y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1aba1722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8282, 4)\n",
      "(2071, 4)\n",
      "(8282, 1)\n",
      "(2071, 1)\n",
      "/****************************/\n",
      "(4, 8282)\n",
      "(4, 2071)\n",
      "(1, 8282)\n",
      "(1, 2071)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "print('/****************************/')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3f3085a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,593\n",
      "Trainable params: 6,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=4))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='softmax'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "#Y_train = np.asarray(Y_train).astype('float32')\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer='adam',  loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "#learning_rate=0.02\n",
    "#opt=tf.keras.optimizers.Adam(learning_rate)\n",
    "#model.compile(loss = \"binary_crossentropy\", optimizer = opt,metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#[print(i.shape, i.dtype) for i in X_train]\n",
    "#[print(o.shape, o.dtype) for o in Y_train]\n",
    "#[print(l.name, l.input_shape, l.dtype) for l in model.layers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9926b383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6211, 4)\n",
      "(6211, 1)\n",
      "Epoch 1/5\n",
      "98/98 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "history = model.fit(X_train, Y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2f5c669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(Y_test)):\n",
    "    test.append(np.argmax(Y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "915fb309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred,test)\n",
    "display(a)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "75165ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "515/515 [==============================] - 4s 7ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 2/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 3/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 4/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 5/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 6/20\n",
      "515/515 [==============================] - 4s 7ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 7/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 8/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 9/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 10/20\n",
      "515/515 [==============================] - 3s 7ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 11/20\n",
      "515/515 [==============================] - 4s 7ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 12/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 13/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 14/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 15/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 16/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 17/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 18/20\n",
      "515/515 [==============================] - 4s 7ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 19/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n",
      "Epoch 20/20\n",
      "515/515 [==============================] - 3s 6ms/step - loss: nan - accuracy: 0.8876 - val_loss: nan - val_accuracy: 0.8865\n"
     ]
    }
   ],
   "source": [
    "X_test = np.asarray(X_test).astype('float32')\n",
    "Y_test = np.asarray(Y_test).astype('float32')\n",
    "\n",
    "history = model.fit(X_train, Y_train,validation_data = (X_test,Y_test), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d40f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
